{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e817d3-fbc1-4ed8-a4b0-f61cfa9f66f2",
   "metadata": {},
   "source": [
    "# README.md\n",
    "## 测试机器\n",
    "Mac M2\n",
    "- vcpu 8\n",
    "- memory 16G\n",
    "## 安装程序\n",
    "- python 3.12\n",
    "- Bio 1.7.1\n",
    "- cutadapt 4.9\n",
    "- vsearch v2.30.0\n",
    "- FastQC v0.12.1\n",
    "- trimmomatic 0.39\n",
    "## 运行\n",
    "依次执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aee67b4-28e1-43ba-b2a6-df53aef64c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import csv\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c71904b-b355-40c5-bcfa-774b2d226ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_QC(input_r1, input_r2, output_dir, primer_f=\"\", primer_r=\"\"):\n",
    "    \"\"\"\n",
    "    执行严格的NGS数据质控流程\n",
    "    :param input_r1: Read1输入文件路径\n",
    "    :param input_r2: Read2输入文件路径\n",
    "    :param output_dir: 输出目录\n",
    "    :param primer_f: 正向引物序列（可选）\n",
    "    :param primer_r: 反向引物序列（可选）\n",
    "    \"\"\"\n",
    "    # 定义接头序列\n",
    "    adapter_r1 = \"AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\"  # P7 adapter for read1\n",
    "    adapter_r2 = \"AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT\"  # P5 adapter for read2\n",
    "\n",
    "    subprocess.run([\"mkdir\", \"-p\", f\"{output_dir}/fastqc_raw\"])\n",
    "    subprocess.run([\"mkdir\", \"-p\", f\"{output_dir}/fastqc_trimmed\"])\n",
    "    \n",
    "    # FastQC原始数据质控\n",
    "    subprocess.run([\"fastqc\", \"-t\", \"14\", input_r1, input_r2, \"-o\", f\"{output_dir}/fastqc_raw\"])\n",
    "    \n",
    "    # cutadapt切除接头与引物\n",
    "    cutadapt_cmd = [\n",
    "            \"cutadapt\",\n",
    "            \"-a\", adapter_r2,  # R2的3'端接头（P5）\n",
    "            \"-A\", adapter_r1,  # R1的3'端接头（P7）\n",
    "            \"-o\", f\"{output_dir}/F.fq.gz\",\n",
    "            \"-p\", f\"{output_dir}/R.fq.gz\",\n",
    "            \"--minimum-length\", \"50\",\n",
    "            \"--max-n\", \"0\",\n",
    "            \"--error-rate\", \"0.1\",\n",
    "            f\"--json={output_dir}/cutadapt.json\",\n",
    "            \"--cores=14\"\n",
    "        ]\n",
    "        \n",
    "    # 添加引物切除参数\n",
    "    if primer_f and primer_r:\n",
    "        cutadapt_cmd.extend([\"-g\", f\"^{primer_f}\", \"-G\", f\"^{primer_r}\"])\n",
    "    \n",
    "    cutadapt_cmd.extend([input_r1, input_r2])\n",
    "    \n",
    "    subprocess.run(cutadapt_cmd)\n",
    "    \n",
    "    # 切除后质控验证\n",
    "    try:\n",
    "        with open(f\"{output_dir}/cutadapt.json\") as f:\n",
    "            log_data = json.load(f)\n",
    "            \n",
    "        total_pairs = log_data[\"read_counts\"][\"input\"]\n",
    "        kept_pairs = log_data[\"read_counts\"][\"output\"]\n",
    "        kept_ratio = kept_pairs / total_pairs * 100\n",
    "        \n",
    "        print(f\"原始序列对: {total_pairs}\")\n",
    "        print(f\"保留序列对: {kept_pairs} ({kept_ratio:.2f}%)\")\n",
    "        \n",
    "        # 验证标准\n",
    "        if kept_ratio < 90:\n",
    "            print(\"\\n⚠️ 警告: 保留率低于90%，建议检查接头/引物设计\")\n",
    "        else:\n",
    "            print(\"\\n✅ 保留率符合质控标准(>90%)\")\n",
    "                \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON解析失败: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ cutadapt.json文件未生成，请检查命令执行\")\n",
    "    except KeyError as e:\n",
    "        print(f\"❌ JSON结构异常，缺失关键字段: {e}\")\n",
    "    \n",
    "    # 额外质控：切除后FastQC验证\n",
    "    subprocess.run([\n",
    "        \"fastqc\", \n",
    "        \"-t\", \"14\",\n",
    "        f\"{output_dir}/F.fq.gz\", \n",
    "        f\"{output_dir}/R.fq.gz\",\n",
    "        \"-o\", f\"{output_dir}/fastqc_trimmed\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09dbce8-73e3-4e9a-8680-0055fd091da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merget(input_forward,input_reverse,output_merged):\n",
    "    vsearch_command = f\"vsearch --fastq_mergepairs {input_forward} --reverse {input_reverse} --fastqout {output_merged} --fastq_allowmergestagger\"\n",
    "    subprocess.run(vsearch_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4997126-f950-4cb1-bb77-8943abf7d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QC_merger(input_fastq,output_dir,output_fastq):\n",
    "    subprocess.run([\"mkdir\", \"-p\", output_dir])\n",
    "    subprocess.run([\"fastqc\", \"-t\", \"14\", input_fastq, \"-o\", output_dir])\n",
    "    subprocess.run([\"trimmomatic\", \"SE\", \"-threads\", \"14\", \"-phred33\", input_fastq, output_fastq, \"LEADING:3\", \"TRAILING:3\", \"SLIDINGWINDOW:4:15\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9126988-3a6b-4c2f-9391-7cb343d1e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarcodeClassifier:\n",
    "    def __init__(self, input_fastq, csv_file, output_directory):\n",
    "        self.input_fastq = input_fastq\n",
    "        self.csv_file = csv_file\n",
    "        self.output_directory = output_directory\n",
    "        self.barcode_pairs = self.read_barcodes_from_csv()\n",
    "        self.barcode_handles = {}\n",
    "\n",
    "    def read_barcodes_from_csv(self):\n",
    "\n",
    "        barcode_pairs = []\n",
    "        with open(self.csv_file, 'r') as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            next(csvreader)  # 跳过标题\n",
    "            for row in csvreader:\n",
    "                barcode1, barcode2 = row[0].strip(), row[1].strip()\n",
    "                barcode_pairs.append((barcode1, barcode2))\n",
    "        return barcode_pairs\n",
    "\n",
    "    def correct_sequence(self, sequence):\n",
    "        \n",
    "        base_F = \"ATCG\"\n",
    "        base_R = \"TAGC\"\n",
    "        complement = {f: r for f, r in zip(base_F, base_R)}\n",
    "        return ''.join(complement.get(base, base) for base in reversed(sequence))\n",
    "\n",
    "    def classify_by_barcodes(self):\n",
    "        unmatched_handle = open(os.path.join(self.output_directory, \"unmatched_output.fastq\"), \"w\")\n",
    "\n",
    "        with open(self.input_fastq, \"r\") as handle:\n",
    "            for record in SeqIO.parse(handle, \"fastq\"):\n",
    "                found_match = False\n",
    "                for barcode1, barcode2 in self.barcode_pairs:\n",
    "                    if str(record.seq).startswith(barcode1) and str(record.seq).endswith(barcode2):\n",
    "                        barcode_pair_name = f\"{barcode1}_{barcode2}\"\n",
    "                        if barcode_pair_name not in self.barcode_handles:\n",
    "                            self.barcode_handles[barcode_pair_name] = open(os.path.join(self.output_directory, f\"{barcode_pair_name}_output.fastq\"), \"w\")\n",
    "                        SeqIO.write(record, self.barcode_handles[barcode_pair_name], \"fastq\")\n",
    "                        found_match = True\n",
    "                        break\n",
    "\n",
    "                if not found_match:\n",
    "                    corrected_seq = self.correct_sequence(str(record.seq))\n",
    "                    for barcode1, barcode2 in self.barcode_pairs:\n",
    "                        if corrected_seq.startswith(barcode1) and corrected_seq.endswith(barcode2):\n",
    "                            barcode_pair_name = f\"{barcode1}_{barcode2}\"\n",
    "                            if barcode_pair_name not in self.barcode_handles:\n",
    "                                self.barcode_handles[barcode_pair_name] = open(os.path.join(self.output_directory, f\"{barcode_pair_name}_output.fastq\"), \"w\")\n",
    "\n",
    "                            # 创建一个包含修正序列的新SeqRecord\n",
    "                            corrected_record = SeqRecord(Seq(corrected_seq), id=record.id, description=record.description, letter_annotations={\"phred_quality\": record.letter_annotations['phred_quality']})\n",
    "                            SeqIO.write(corrected_record, self.barcode_handles[barcode_pair_name], \"fastq\")\n",
    "                            found_match = True\n",
    "                            break\n",
    "\n",
    "                if not found_match:\n",
    "                    SeqIO.write(record, unmatched_handle, \"fastq\")\n",
    "\n",
    "        for handle in self.barcode_handles.values():\n",
    "            handle.close()\n",
    "        unmatched_handle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd3e904-21e0-4ac7-9afb-1dc2bbeade7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sequences(config_file):\n",
    "    with open(config_file, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)  # 跳过标题\n",
    "        for row in csvreader:\n",
    "            barcode1 = row[0].strip()\n",
    "            barcode2 = row[1].strip()\n",
    "            template = row[2].strip().upper()\n",
    "            spacer = row[3].strip().upper()\n",
    "            start_base = int(row[4].strip())\n",
    "            end_base = int(row[5].strip())\n",
    "            ind = template.index(spacer)\n",
    "            sequences = []\n",
    "            file_path = file + \"/\" + barcode1 + \"_\" + barcode2 + \"_output.fastq\"\n",
    "            with open(file_path, \"r\") as seq_file:\n",
    "                line_number = 0\n",
    "                for line in seq_file:\n",
    "                    line_number += 1\n",
    "                    if line_number % 4 == 2:\n",
    "                        sequence = line.strip()\n",
    "                        extracted_sequence = sequence[ind+start_base:ind+end_base]\n",
    "                        sequences.append(extracted_sequence)\n",
    "    \n",
    "            sequence_counts = Counter(sequences)\n",
    "    \n",
    "            output_file_path = file_path.replace('.fastq', '_counts.csv')\n",
    "    \n",
    "            with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "                writer = csv.writer(output_csvfile)\n",
    "                writer.writerow(['Extracted Sequence', 'Count'])  \n",
    "                for seq, count in sequence_counts.items():\n",
    "                    writer.writerow([seq, count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2afa1bc8-dd47-4572-ab02-d4f2d00e147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_base_counts(config_file, output_file):\n",
    "    results = []\n",
    "    with open(config_file, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)  # 跳过标题\n",
    "        for row in csvreader:\n",
    "            barcode1 = row[0].strip()\n",
    "            barcode2 = row[1].strip()\n",
    "            template = row[2].strip().upper()\n",
    "            spacer = row[3].strip().upper()\n",
    "            base_windows = int(row[6].strip())\n",
    "            file_path = file_1 + \"/\" + barcode1 + \"_\" + barcode2 + \"_output.fastq\"\n",
    "            sequences = [] \n",
    "            with open(file_path, 'r') as file:\n",
    "                line_number = 0\n",
    "\n",
    "    \n",
    "                for line in file:\n",
    "                    line_number += 1\n",
    "                    if line_number % 4 == 2:\n",
    "                        sequences.append(line.strip())\n",
    "\n",
    "            ind = template.index(spacer)\n",
    "            base_windows_ind = ind + base_windows - 1\n",
    "\n",
    "            num_A = 0\n",
    "            num_T = 0\n",
    "            num_C = 0\n",
    "            num_G = 0\n",
    "\n",
    "            for seq in sequences:\n",
    "                if len(seq) > base_windows_ind:\n",
    "                    if seq[base_windows_ind] == 'A':\n",
    "                        num_A += 1\n",
    "                    elif seq[base_windows_ind] == 'T':\n",
    "                        num_T += 1\n",
    "                    elif seq[base_windows_ind] == 'C':\n",
    "                        num_C += 1\n",
    "                    elif seq[base_windows_ind] == 'G':\n",
    "                        num_G += 1\n",
    "\n",
    "            results.append([file_path, spacer, base_windows, num_A, num_T, num_C, num_G])\n",
    "\n",
    "    # 写入结果到CSV文件\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([ 'Spacer', 'Base Windows', 'A', 'T', 'C', 'G'])\n",
    "        writer.writerows(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7926dc9f-4744-4c13-aa39-1bb5d43e5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NGS(file,purpose):\n",
    "    input_forward  = file + \"/F.fq.gz\"\n",
    "    input_reverse = file + \"/R.fq.gz\"\n",
    "    output_merged = file + \"/merged.fasta\"\n",
    "    merget(input_forward,input_reverse,output_merged)\n",
    "    input_fastq = output_merged\n",
    "    output_dir = file + \"/fastqc_output\"\n",
    "    output_fastq = file + \"/output_trimmed.fastq\"\n",
    "    QC_merger(input_fastq,output_dir,output_fastq)\n",
    "    input_fastq = output_fastq\n",
    "    tempalte_CSV = file + \"/tempalte_CSV.csv\"\n",
    "    output_directory = file \n",
    "    classifier = BarcodeClassifier(input_fastq, tempalte_CSV, output_directory)\n",
    "    classifier.classify_by_barcodes()\n",
    "    if purpose == 1:\n",
    "        config_file = tempalte_CSV\n",
    "        process_sequences(config_file)\n",
    "    elif purpose == 2:\n",
    "        config_file = tempalte_CSV\n",
    "        output_file = file+ \"/results.csv\"\n",
    "        process_base_counts(config_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111df4da-847e-49df-bc8d-5e345a430f3e",
   "metadata": {},
   "source": [
    "上述程序直接点击运行即可，不要进行任何修改，如果想修改的话请复制后进行修改\n",
    "二代测序数据下载后请自行解压，并且把文件名修改为F.fq和R.fq\n",
    "上传后确定文件夹后，在file中输入上传的路径，注意所有的后续文件都会有在这个文件夹中生成，建议每次都新建一个文件夹\n",
    "purpose只有两个选项有意义，1或者2，1是针对spacer定位的区域进行扫描，2是针对碱基编辑器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf53737-af4d-4a15-a28e-f3d9b448d104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application/gzip\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of X-LHF0186_L2_1.fq.gz\n",
      "Started analysis of X-LHF0186_L2_2.fq.gz\n",
      "Approx 5% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 5% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 10% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 10% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 15% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 15% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 20% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 20% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 25% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 25% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 30% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 30% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 35% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 35% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 40% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 40% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 45% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 45% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 50% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 50% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 55% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 55% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 60% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 60% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 65% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 65% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 70% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 70% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 75% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 75% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 80% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 80% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 85% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 85% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 90% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 90% complete for X-LHF0186_L2_2.fq.gz\n",
      "Approx 95% complete for X-LHF0186_L2_1.fq.gz\n",
      "Approx 95% complete for X-LHF0186_L2_2.fq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for X-LHF0186_L2_1.fq.gz\n",
      "Analysis complete for X-LHF0186_L2_2.fq.gz\n",
      "This is cutadapt 4.9 with Python 3.12.11\n",
      "Command line parameters: -a AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -A AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC -o ./data3/F.fq.gz -p ./data3/R.fq.gz --minimum-length 50 --max-n 0 --error-rate 0.1 --json=./data3/cutadapt.json --cores=14 ./data3/X-LHF0186_L2_1.fq.gz ./data3/X-LHF0186_L2_2.fq.gz\n",
      "Processing paired-end reads on 14 cores ...\n",
      "Finished in 152.301 s (10.934 µs/read; 5.49 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total read pairs processed:         13,929,232\n",
      "  Read 1 with adapter:              10,710,959 (76.9%)\n",
      "  Read 2 with adapter:              10,675,003 (76.6%)\n",
      "\n",
      "== Read fate breakdown ==\n",
      "Pairs that were too short:                   0 (0.0%)\n",
      "Pairs with too many N:                  16,616 (0.1%)\n",
      "Pairs written (passing filters):    13,912,616 (99.9%)\n",
      "\n",
      "Total basepairs processed: 4,178,769,600 bp\n",
      "  Read 1: 2,089,384,800 bp\n",
      "  Read 2: 2,089,384,800 bp\n",
      "Total written (filtered):  3,972,322,691 bp (95.1%)\n",
      "  Read 1: 1,985,938,264 bp\n",
      "  Read 2: 1,986,384,427 bp\n",
      "\n",
      "=== First read: Adapter 1 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT; Type: regular 3'; Length: 33; Trimmed: 10710959 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1; 20-29 bp: 2; 30-33 bp: 3\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 1.7%\n",
      "  C: 39.0%\n",
      "  G: 17.1%\n",
      "  T: 42.2%\n",
      "  none/other: 0.0%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t1959\t217644.2\t0\t1959\n",
      "4\t157\t54411.1\t0\t157\n",
      "5\t1128\t13602.8\t0\t1128\n",
      "6\t115\t3400.7\t0\t115\n",
      "7\t469\t850.2\t0\t469\n",
      "8\t22780\t212.5\t0\t22780\n",
      "9\t8781754\t53.1\t0\t8745480 36274\n",
      "10\t481551\t13.3\t1\t474785 6766\n",
      "11\t698192\t3.3\t1\t687551 10641\n",
      "12\t250730\t0.8\t1\t246613 4117\n",
      "13\t272503\t0.2\t1\t269027 3476\n",
      "14\t199372\t0.1\t1\t45 199327\n",
      "15\t234\t0.0\t1\t0 234\n",
      "16\t6\t0.0\t1\t0 6\n",
      "17\t2\t0.0\t1\t0 2\n",
      "18\t3\t0.0\t1\t0 3\n",
      "20\t4\t0.0\t2\t0 0 4\n",
      "\n",
      "\n",
      "=== Second read: Adapter 2 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC; Type: regular 3'; Length: 34; Trimmed: 10675003 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1; 20-29 bp: 2; 30-34 bp: 3\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 1.7%\n",
      "  C: 38.9%\n",
      "  G: 17.2%\n",
      "  T: 42.2%\n",
      "  none/other: 0.0%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t14170\t217644.2\t0\t14170\n",
      "4\t1043\t54411.1\t0\t1043\n",
      "5\t2000\t13602.8\t0\t2000\n",
      "6\t165\t3400.7\t0\t165\n",
      "7\t473\t850.2\t0\t473\n",
      "8\t22555\t212.5\t0\t22555\n",
      "9\t8743152\t53.1\t0\t8588594 154558\n",
      "10\t480722\t13.3\t1\t465505 15217\n",
      "11\t697038\t3.3\t1\t673769 23269\n",
      "12\t250260\t0.8\t1\t241035 9225\n",
      "13\t267737\t0.2\t1\t262942 4795\n",
      "14\t194832\t0.1\t1\t77 194755\n",
      "15\t720\t0.0\t1\t2 718\n",
      "16\t135\t0.0\t1\t0 135\n",
      "20\t1\t0.0\t2\t0 0 1\n",
      "原始序列对: 13929232\n",
      "保留序列对: 13912616 (99.88%)\n",
      "\n",
      "✅ 保留率符合质控标准(>90%)\n",
      "application/gzip\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of F.fq.gz\n",
      "Started analysis of R.fq.gz\n",
      "Approx 5% complete for F.fq.gz\n",
      "Approx 5% complete for R.fq.gz\n",
      "Approx 10% complete for F.fq.gz\n",
      "Approx 10% complete for R.fq.gz\n",
      "Approx 15% complete for F.fq.gz\n",
      "Approx 15% complete for R.fq.gz\n",
      "Approx 20% complete for F.fq.gz\n",
      "Approx 20% complete for R.fq.gz\n",
      "Approx 25% complete for F.fq.gz\n",
      "Approx 25% complete for R.fq.gz\n",
      "Approx 30% complete for F.fq.gz\n",
      "Approx 30% complete for R.fq.gz\n",
      "Approx 35% complete for F.fq.gz\n",
      "Approx 35% complete for R.fq.gz\n",
      "Approx 40% complete for F.fq.gz\n",
      "Approx 40% complete for R.fq.gz\n",
      "Approx 45% complete for F.fq.gz\n",
      "Approx 45% complete for R.fq.gz\n",
      "Approx 50% complete for F.fq.gz\n",
      "Approx 50% complete for R.fq.gz\n",
      "Approx 55% complete for F.fq.gz\n",
      "Approx 55% complete for R.fq.gz\n",
      "Approx 60% complete for F.fq.gz\n",
      "Approx 60% complete for R.fq.gz\n",
      "Approx 65% complete for F.fq.gz\n",
      "Approx 65% complete for R.fq.gz\n",
      "Approx 70% complete for F.fq.gz\n",
      "Approx 70% complete for R.fq.gz\n",
      "Approx 75% complete for F.fq.gz\n",
      "Approx 75% complete for R.fq.gz\n",
      "Approx 80% complete for F.fq.gz\n",
      "Approx 80% complete for R.fq.gz\n",
      "Approx 85% complete for F.fq.gz\n",
      "Approx 85% complete for R.fq.gz\n",
      "Approx 90% complete for F.fq.gz\n",
      "Approx 90% complete for R.fq.gz\n",
      "Approx 95% complete for F.fq.gz\n",
      "Approx 95% complete for R.fq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for F.fq.gz\n",
      "Analysis complete for R.fq.gz\n"
     ]
    }
   ],
   "source": [
    "strict_QC('./data3/X-LHF0186_L2_1.fq.gz', './data3/X-LHF0186_L2_2.fq.gz', './data3', primer_f=\"\", primer_r=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b93eac-715c-4890-97c6-faf6042522cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./data3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf26b36-31a6-4ff1-b757-76509f5e1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbd44b86-7d26-45ad-9689-4eb975810013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vsearch v2.30.0_macos_aarch64, 16.0GB RAM, 8 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Merging reads 100%\n",
      "  13912616  Pairs\n",
      "  13853442  Merged (99.6%)\n",
      "     59174  Not merged (0.4%)\n",
      "\n",
      "Pairs that failed merging due to various reasons:\n",
      "     25546  too few kmers found on same diagonal\n",
      "       553  multiple potential alignments\n",
      "     14398  too many differences\n",
      "     18658  alignment score too low, or score drop too high\n",
      "        19  overlap too short\n",
      "\n",
      "Statistics of all reads:\n",
      "    142.76  Mean read length\n",
      "\n",
      "Statistics of merged reads:\n",
      "    148.66  Mean fragment length\n",
      "     26.57  Standard deviation of fragment length\n",
      "      0.12  Mean expected error in forward sequences\n",
      "      0.12  Mean expected error in reverse sequences\n",
      "      0.03  Mean expected error in merged sequences\n",
      "      0.05  Mean observed errors in merged region of forward sequences\n",
      "      0.04  Mean observed errors in merged region of reverse sequences\n",
      "      0.08  Mean observed errors in merged region\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biosequence/fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of merged.fasta\n",
      "Approx 5% complete for merged.fasta\n",
      "Approx 10% complete for merged.fasta\n",
      "Approx 15% complete for merged.fasta\n",
      "Approx 20% complete for merged.fasta\n",
      "Approx 25% complete for merged.fasta\n",
      "Approx 30% complete for merged.fasta\n",
      "Approx 35% complete for merged.fasta\n",
      "Approx 40% complete for merged.fasta\n",
      "Approx 45% complete for merged.fasta\n",
      "Approx 50% complete for merged.fasta\n",
      "Approx 55% complete for merged.fasta\n",
      "Approx 60% complete for merged.fasta\n",
      "Approx 65% complete for merged.fasta\n",
      "Approx 70% complete for merged.fasta\n",
      "Approx 75% complete for merged.fasta\n",
      "Approx 80% complete for merged.fasta\n",
      "Approx 85% complete for merged.fasta\n",
      "Approx 90% complete for merged.fasta\n",
      "Approx 95% complete for merged.fasta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for merged.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TrimmomaticSE: Started with arguments:\n",
      " -threads 14 -phred33 ./data3/merged.fasta ./data3/output_trimmed.fastq LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15\n",
      "Input Reads: 13853442 Surviving: 13853283 (100.00%) Dropped: 159 (0.00%)\n",
      "TrimmomaticSE: Completed successfully\n"
     ]
    }
   ],
   "source": [
    "NGS(file,purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a26fe-2bc9-4792-be49-f4397c6089c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
