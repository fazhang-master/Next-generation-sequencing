{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e817d3-fbc1-4ed8-a4b0-f61cfa9f66f2",
   "metadata": {},
   "source": [
    "# README.md\n",
    "## 测试机器\n",
    "Mac M2\n",
    "- vcpu 8\n",
    "- memory 16G\n",
    "## 安装程序\n",
    "- python 3.12\n",
    "- Bio 1.7.1\n",
    "- cutadapt 4.9\n",
    "- vsearch v2.30.0\n",
    "- FastQC v0.12.1\n",
    "- trimmomatic 0.39\n",
    "## 运行\n",
    "依次执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aee67b4-28e1-43ba-b2a6-df53aef64c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import csv\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import tqdm\n",
    "import os\n",
    "import json\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c71904b-b355-40c5-bcfa-774b2d226ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_QC(input_r1, input_r2, output_dir, primer_f=\"\", primer_r=\"\"):\n",
    "    \"\"\"\n",
    "    执行严格的NGS数据质控流程\n",
    "    :param input_r1: Read1输入文件路径\n",
    "    :param input_r2: Read2输入文件路径\n",
    "    :param output_dir: 输出目录\n",
    "    :param primer_f: 正向引物序列（可选）\n",
    "    :param primer_r: 反向引物序列（可选）\n",
    "    \"\"\"\n",
    "    # 定义接头序列\n",
    "    adapter_r1 = \"AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\"  # P7 adapter for read1\n",
    "    adapter_r2 = \"AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT\"  # P5 adapter for read2\n",
    "\n",
    "    subprocess.run([\"mkdir\", \"-p\", f\"{output_dir}/fastqc_raw\"])\n",
    "    subprocess.run([\"mkdir\", \"-p\", f\"{output_dir}/fastqc_trimmed\"])\n",
    "    \n",
    "    # FastQC原始数据质控\n",
    "    subprocess.run([\"fastqc\", \"-t\", \"14\", input_r1, input_r2, \"-o\", f\"{output_dir}/fastqc_raw\"])\n",
    "    \n",
    "    # cutadapt切除接头与引物\n",
    "    cutadapt_cmd = [\n",
    "            \"cutadapt\",\n",
    "            \"-a\", adapter_r2,  # R2的3'端接头（P5）\n",
    "            \"-A\", adapter_r1,  # R1的3'端接头（P7）\n",
    "            \"-o\", f\"{output_dir}/F.fq.gz\",\n",
    "            \"-p\", f\"{output_dir}/R.fq.gz\",\n",
    "            \"--minimum-length\", \"50\",\n",
    "            \"--max-n\", \"0\",\n",
    "            \"--error-rate\", \"0.1\",\n",
    "            f\"--json={output_dir}/cutadapt.json\",\n",
    "            \"--cores=14\"\n",
    "        ]\n",
    "        \n",
    "    # 添加引物切除参数\n",
    "    if primer_f and primer_r:\n",
    "        cutadapt_cmd.extend([\"-g\", f\"^{primer_f}\", \"-G\", f\"^{primer_r}\"])\n",
    "    \n",
    "    cutadapt_cmd.extend([input_r1, input_r2])\n",
    "    \n",
    "    subprocess.run(cutadapt_cmd)\n",
    "    \n",
    "    # 切除后质控验证\n",
    "    try:\n",
    "        with open(f\"{output_dir}/cutadapt.json\") as f:\n",
    "            log_data = json.load(f)\n",
    "            \n",
    "        total_pairs = log_data[\"read_counts\"][\"input\"]\n",
    "        kept_pairs = log_data[\"read_counts\"][\"output\"]\n",
    "        kept_ratio = kept_pairs / total_pairs * 100\n",
    "        \n",
    "        print(f\"原始序列对: {total_pairs}\")\n",
    "        print(f\"保留序列对: {kept_pairs} ({kept_ratio:.2f}%)\")\n",
    "        \n",
    "        # 验证标准\n",
    "        if kept_ratio < 90:\n",
    "            print(\"\\n⚠️ 警告: 保留率低于90%，建议检查接头/引物设计\")\n",
    "        else:\n",
    "            print(\"\\n✅ 保留率符合质控标准(>90%)\")\n",
    "                \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON解析失败: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ cutadapt.json文件未生成，请检查命令执行\")\n",
    "    except KeyError as e:\n",
    "        print(f\"❌ JSON结构异常，缺失关键字段: {e}\")\n",
    "    \n",
    "    # 额外质控：切除后FastQC验证\n",
    "    subprocess.run([\n",
    "        \"fastqc\", \n",
    "        \"-t\", \"14\",\n",
    "        f\"{output_dir}/F.fq.gz\", \n",
    "        f\"{output_dir}/R.fq.gz\",\n",
    "        \"-o\", f\"{output_dir}/fastqc_trimmed\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09dbce8-73e3-4e9a-8680-0055fd091da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merget(input_forward, input_reverse, output_merged):\n",
    "    \"\"\"合并双端测序数据，若输出文件已存在则跳过\"\"\"\n",
    "    # 检查输出文件是否已存在\n",
    "    if os.path.exists(output_merged):\n",
    "        print(f\"文件 {output_merged} 已存在，跳过合并操作\")\n",
    "        return\n",
    "    \n",
    "    # 检查输入文件是否存在\n",
    "    if not os.path.exists(input_forward):\n",
    "        raise FileNotFoundError(f\"正向文件不存在: {input_forward}\")\n",
    "    if not os.path.exists(input_reverse):\n",
    "        raise FileNotFoundError(f\"反向文件不存在: {input_reverse}\")\n",
    "    \n",
    "    # 构建并执行VSEARCH命令\n",
    "    vsearch_command = (\n",
    "        f\"vsearch --fastq_mergepairs {input_forward} \"\n",
    "        f\"--reverse {input_reverse} \"\n",
    "        f\"--fastqout {output_merged} \"\n",
    "        \"--fastq_allowmergestagger\"\n",
    "    )\n",
    "    subprocess.run(vsearch_command, shell=True, check=True)\n",
    "    print(f\"双端合并完成 → {output_merged}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4997126-f950-4cb1-bb77-8943abf7d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QC_merger(input_fastq, output_dir, output_fastq):\n",
    "    # 检查输出文件是否已存在（若存在则跳过）\n",
    "    if os.path.exists(output_fastq):\n",
    "        print(f\"文件 {output_fastq} 已存在，跳过质量控制和修剪步骤\")\n",
    "        return\n",
    "    \n",
    "    # 创建输出目录（若不存在）\n",
    "    subprocess.run([\"mkdir\", \"-p\", output_dir])\n",
    "    \n",
    "    # 执行FastQC质量控制\n",
    "    subprocess.run([\n",
    "        \"fastqc\", \n",
    "        \"-t\", \"14\", \n",
    "        input_fastq, \n",
    "        \"-o\", output_dir\n",
    "    ])\n",
    "    \n",
    "    # 执行Trimmomatic修剪\n",
    "    subprocess.run([\n",
    "        \"trimmomatic\", \"SE\", \n",
    "        \"-threads\", \"14\", \n",
    "        \"-phred33\", \n",
    "        input_fastq, \n",
    "        output_fastq, \n",
    "        \"LEADING:3\", \n",
    "        \"TRAILING:3\", \n",
    "        \"SLIDINGWINDOW:4:15\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9126988-3a6b-4c2f-9391-7cb343d1e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarcodeClassifier:\n",
    "    def __init__(self, input_fastq, csv_file, output_directory):\n",
    "        self.input_fastq = input_fastq\n",
    "        self.csv_file = csv_file\n",
    "        self.output_directory = output_directory\n",
    "        self.barcode_pairs = self.read_barcodes_from_csv()\n",
    "        self.barcode_handles = {}\n",
    "        # 创建输出目录（如果不存在）\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    def read_barcodes_from_csv(self):\n",
    "        \"\"\"从CSV文件中读取条形码组合\"\"\"\n",
    "        barcode_pairs = []\n",
    "        with open(self.csv_file, 'r') as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            next(csvreader)  # 跳过标题行\n",
    "            for row in csvreader:\n",
    "                barcode1, barcode2 = row[0].strip(), row[1].strip()\n",
    "                barcode_pairs.append((barcode1, barcode2))\n",
    "        return barcode_pairs\n",
    "\n",
    "    def correct_sequence(self, sequence):\n",
    "        \"\"\"校正反向互补序列\"\"\"\n",
    "        base_F = \"ATCG\"\n",
    "        base_R = \"TAGC\"\n",
    "        complement = {f: r for f, r in zip(base_F, base_R)}\n",
    "        return ''.join(complement.get(base, base) for base in reversed(sequence))\n",
    "\n",
    "    def output_files_exist(self):\n",
    "        \"\"\"检查所有输出文件是否已存在\"\"\"\n",
    "        # 检查未匹配序列文件\n",
    "        unmatched_file = os.path.join(self.output_directory, \"unmatched_output.fastq\")\n",
    "        if not os.path.exists(unmatched_file):\n",
    "            return False\n",
    "        \n",
    "        # 检查每个条形码的输出文件\n",
    "        for barcode1, barcode2 in self.barcode_pairs:\n",
    "            barcode_file = os.path.join(\n",
    "                self.output_directory, \n",
    "                f\"{barcode1}_{barcode2}_output.fastq\"\n",
    "            )\n",
    "            if not os.path.exists(barcode_file):\n",
    "                return False\n",
    "                \n",
    "        return True\n",
    "\n",
    "    def classify_by_barcodes(self):\n",
    "        \"\"\"执行条形码分类（如果输出文件不存在）\"\"\"\n",
    "        # 检查所有输出文件是否已存在\n",
    "        if self.output_files_exist():\n",
    "            print(\"所有输出文件已存在，跳过分类操作。\")\n",
    "            return\n",
    "            \n",
    "        # 打开未匹配序列文件\n",
    "        unmatched_handle = open(os.path.join(self.output_directory, \"unmatched_output.fastq\"), \"w\")\n",
    "        \n",
    "        with open(self.input_fastq, \"r\") as handle:\n",
    "            for record in tqdm.tqdm(SeqIO.parse(handle, \"fastq\"), desc=\"Processing sequences\"):\n",
    "                found_match = False\n",
    "                \n",
    "                # 正向匹配\n",
    "                for barcode1, barcode2 in self.barcode_pairs:\n",
    "                    if str(record.seq).startswith(barcode1) and str(record.seq).endswith(barcode2):\n",
    "                        self._write_record(record, barcode1, barcode2)\n",
    "                        found_match = True\n",
    "                        break\n",
    "                \n",
    "                # 反向互补匹配\n",
    "                if not found_match:\n",
    "                    corrected_seq = self.correct_sequence(str(record.seq))\n",
    "                    for barcode1, barcode2 in self.barcode_pairs:\n",
    "                        if corrected_seq.startswith(barcode1) and corrected_seq.endswith(barcode2):\n",
    "                            self._write_corrected_record(record, corrected_seq, barcode1, barcode2)\n",
    "                            found_match = True\n",
    "                            break\n",
    "                \n",
    "                # 未匹配序列\n",
    "                if not found_match:\n",
    "                    SeqIO.write(record, unmatched_handle, \"fastq\")\n",
    "\n",
    "        # 关闭所有文件句柄\n",
    "        for handle in self.barcode_handles.values():\n",
    "            handle.close()\n",
    "        unmatched_handle.close()\n",
    "    \n",
    "    def _write_record(self, record, barcode1, barcode2):\n",
    "        \"\"\"写入匹配的序列记录\"\"\"\n",
    "        barcode_pair_name = f\"{barcode1}_{barcode2}\"\n",
    "        if barcode_pair_name not in self.barcode_handles:\n",
    "            file_path = os.path.join(self.output_directory, f\"{barcode_pair_name}_output.fastq\")\n",
    "            self.barcode_handles[barcode_pair_name] = open(file_path, \"w\")\n",
    "        SeqIO.write(record, self.barcode_handles[barcode_pair_name], \"fastq\")\n",
    "    \n",
    "    def _write_corrected_record(self, record, corrected_seq, barcode1, barcode2):\n",
    "        \"\"\"写入校正后的序列记录\"\"\"\n",
    "        barcode_pair_name = f\"{barcode1}_{barcode2}\"\n",
    "        if barcode_pair_name not in self.barcode_handles:\n",
    "            file_path = os.path.join(self.output_directory, f\"{barcode_pair_name}_output.fastq\")\n",
    "            self.barcode_handles[barcode_pair_name] = open(file_path, \"w\")\n",
    "        \n",
    "        # 创建校正后的记录（保留质量值）\n",
    "        corrected_record = SeqRecord(\n",
    "            Seq(corrected_seq),\n",
    "            id=record.id,\n",
    "            description=record.description,\n",
    "            letter_annotations={\"phred_quality\": record.letter_annotations['phred_quality']}\n",
    "        )\n",
    "        SeqIO.write(corrected_record, self.barcode_handles[barcode_pair_name], \"fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd3e904-21e0-4ac7-9afb-1dc2bbeade7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sequences(config_file):\n",
    "    with open(config_file, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)  # 跳过标题\n",
    "        for row in tqdm.tqdm(csvreader):\n",
    "            barcode1 = row[0].strip()\n",
    "            barcode2 = row[1].strip()\n",
    "            template = row[2].strip().upper()\n",
    "            spacer = row[3].strip().upper()\n",
    "            start_base = int(row[4].strip())\n",
    "            end_base = int(row[5].strip())\n",
    "            ind = template.index(spacer)\n",
    "            sequences = [] \n",
    "            file_path = os.path.join(file, f\"{barcode1}_{barcode2}_output.fastq\")\n",
    "            with open(file_path, \"r\") as seq_file:\n",
    "                line_number = 0\n",
    "                for line in seq_file:\n",
    "                    line_number += 1\n",
    "                    if line_number % 4 == 2:\n",
    "                        sequence = line.strip()\n",
    "                        extracted_sequence = sequence[ind+start_base:ind+end_base]\n",
    "                        sequences.append(extracted_sequence)\n",
    "    \n",
    "            sequence_counts = Counter(sequences)\n",
    "\n",
    "            os.makedirs(os.path.join(file, \"ExtractSeq\"), exist_ok=True)\n",
    "            output_file_path = os.path.join(file, \"ExtractSeq\", os.path.basename(file_path).replace('.fastq', '_counts.csv'))\n",
    "            with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "                writer = csv.writer(output_csvfile)\n",
    "                writer.writerow(['Extracted Sequence', 'Count'])  \n",
    "                for seq, count in sequence_counts.items():\n",
    "                    writer.writerow([seq, count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2afa1bc8-dd47-4572-ab02-d4f2d00e147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_base_counts(config_file, output_file):\n",
    "    results = []\n",
    "    with open(config_file, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)  # 跳过标题\n",
    "        for row in tqdm.tqdm(csvreader):\n",
    "            barcode1 = row[0].strip()\n",
    "            barcode2 = row[1].strip()\n",
    "            template = row[2].strip().upper()\n",
    "            spacer = row[3].strip().upper()\n",
    "            base_windows = int(row[6].strip())\n",
    "            file_path = os.path.join(file, f\"{barcode1}_{barcode2}_output.fastq\")\n",
    "            sequences = [] \n",
    "            with open(file_path, 'r') as countsfile:\n",
    "                line_number = 0\n",
    "\n",
    "    \n",
    "                for line in countsfile:\n",
    "                    line_number += 1\n",
    "                    if line_number % 4 == 2:\n",
    "                        sequences.append(line.strip())\n",
    "\n",
    "            ind = template.index(spacer)\n",
    "            base_windows_ind = ind + base_windows - 1\n",
    "\n",
    "            num_A = 0\n",
    "            num_T = 0\n",
    "            num_C = 0\n",
    "            num_G = 0\n",
    "\n",
    "            for seq in sequences:\n",
    "                if len(seq) > base_windows_ind:\n",
    "                    if seq[base_windows_ind] == 'A':\n",
    "                        num_A += 1\n",
    "                    elif seq[base_windows_ind] == 'T':\n",
    "                        num_T += 1\n",
    "                    elif seq[base_windows_ind] == 'C':\n",
    "                        num_C += 1\n",
    "                    elif seq[base_windows_ind] == 'G':\n",
    "                        num_G += 1\n",
    "\n",
    "            results.append([file_path, spacer, base_windows, num_A, num_T, num_C, num_G])\n",
    "\n",
    "    # 写入结果到CSV文件\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([ 'Spacer', 'Base Windows', 'A', 'T', 'C', 'G'])\n",
    "        writer.writerows(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fdd2fef-263f-4ccb-b0a6-e02be5e44443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_sequences(config_file):\n",
    "    \"\"\"处理序列数据，保存spacer定位后的完整序列\"\"\"\n",
    "    with open(config_file, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)  # 跳过标题行\n",
    "        for row in tqdm.tqdm(csvreader):\n",
    "            # 解析配置参数\n",
    "            barcode1 = row[0].strip()\n",
    "            barcode2 = row[1].strip()\n",
    "            template = row[2].strip().upper()\n",
    "            spacer = row[3].strip().upper()\n",
    "            \n",
    "            # 定位spacer位置（用于验证序列有效性）\n",
    "            try:\n",
    "                ind = template.index(spacer)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            # 构建输入文件路径\n",
    "            file_path = os.path.join(file,f\"{barcode1}_{barcode2}_output.fastq\")\n",
    "            \n",
    "            # 读取并保存完整序列\n",
    "            sequences = []\n",
    "            try:\n",
    "                with open(file_path, \"r\") as seq_file:\n",
    "                    for line_num, line in enumerate(seq_file, 1):\n",
    "                        if line_num % 4 == 2:  # 序列行\n",
    "                            sequences.append(line.strip())\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "                \n",
    "            # 统计序列频率\n",
    "            sequence_counts = Counter(sequences)\n",
    "            \n",
    "            # 输出结果到CSV\n",
    "            os.makedirs(os.path.join(file, \"AllSeq\"), exist_ok=True)\n",
    "            output_file_path = os.path.join(file, \"AllSeq\", os.path.basename(file_path).replace('.fastq', '_counts.csv'))\n",
    "            with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "                writer = csv.writer(output_csvfile)\n",
    "                writer.writerow(['Full Sequence', 'Count'])\n",
    "                for seq, count in sequence_counts.items():\n",
    "                    writer.writerow([seq, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac02d267-c9d4-4333-9146-d2ea2e96c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_surrounding_sequences(config_file, spacer_front=20, spacer_after=20):\n",
    "    \"\"\"处理序列数据，保存spacer定位区域前后特定bp的序列\"\"\"\n",
    "    with open(config_file, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)  # 跳过标题行\n",
    "        for row in tqdm.tqdm(csvreader, desc=\"Processing spacer surrounding sequences\"):\n",
    "            # 解析配置参数\n",
    "            barcode1 = row[0].strip()\n",
    "            barcode2 = row[1].strip()\n",
    "            template = row[2].strip().upper()\n",
    "            spacer = row[3].strip().upper()\n",
    "            \n",
    "            # 定位spacer位置\n",
    "            try:\n",
    "                ind = template.index(spacer)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            # 构建输入文件路径\n",
    "            file_path = os.path.join(file, f\"{barcode1}_{barcode2}_output.fastq\")\n",
    "            \n",
    "            # 读取并处理序列\n",
    "            sequences = []\n",
    "            try:\n",
    "                with open(file_path, \"r\") as seq_file:\n",
    "                    for line_num, line in enumerate(seq_file, 1):\n",
    "                        if line_num % 4 == 2:  # 序列行\n",
    "                            sequence = line.strip()\n",
    "                            # 计算截取范围（含边界保护）\n",
    "                            start_index = max(0, ind - spacer_front)\n",
    "                            end_index = min(len(sequence), ind + len(spacer) + spacer_after)\n",
    "                            extracted_sequence = sequence[start_index:end_index]\n",
    "                            sequences.append(extracted_sequence)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "                \n",
    "            # 统计序列频率\n",
    "            sequence_counts = Counter(sequences)\n",
    "            \n",
    "            # 输出结果到CSV\n",
    "            os.makedirs(os.path.join(file, \"SurroundingSeq\"), exist_ok=True)\n",
    "            output_file_path = os.path.join(\n",
    "                file, \"SurroundingSeq\", \n",
    "                os.path.basename(file_path).replace('.fastq', '_counts.csv')\n",
    "            )\n",
    "            with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "                writer = csv.writer(output_csvfile)\n",
    "                writer.writerow(['Surrounding Sequence', 'Count'])\n",
    "                for seq, count in sequence_counts.items():\n",
    "                    writer.writerow([seq, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7926dc9f-4744-4c13-aa39-1bb5d43e5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NGS(file,purpose,spacer_front=20, spacer_after=20):\n",
    "    input_forward  = file + \"/F.fq.gz\"\n",
    "    input_reverse = file + \"/R.fq.gz\"\n",
    "    output_merged = file + \"/merged.fasta\"\n",
    "    merget(input_forward,input_reverse,output_merged)\n",
    "    input_fastq = output_merged\n",
    "    output_dir = file + \"/fastqc_output\"\n",
    "    output_fastq = file + \"/output_trimmed.fastq\"\n",
    "    QC_merger(input_fastq,output_dir,output_fastq)\n",
    "    input_fastq = output_fastq\n",
    "    tempalte_CSV = \"tempalte_CSV.csv\"\n",
    "    output_directory = file\n",
    "    classifier = BarcodeClassifier(input_fastq, tempalte_CSV, output_directory)\n",
    "    classifier.classify_by_barcodes()\n",
    "    if purpose == 1:\n",
    "        config_file = tempalte_CSV\n",
    "        process_sequences(config_file)\n",
    "    elif purpose == 2:\n",
    "        config_file = tempalte_CSV\n",
    "        output_file = file+ \"/results.csv\"\n",
    "        process_base_counts(config_file, output_file)\n",
    "    elif purpose == 3:\n",
    "        config_file = tempalte_CSV\n",
    "        process_all_sequences(config_file)\n",
    "    elif purpose == 4:\n",
    "        config_file = tempalte_CSV\n",
    "        process_surrounding_sequences(config_file, spacer_front=20, spacer_after=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111df4da-847e-49df-bc8d-5e345a430f3e",
   "metadata": {},
   "source": [
    "上述程序直接点击运行即可，不要进行任何修改，如果想修改的话请复制后进行修改\n",
    "二代测序数据下载后请自行解压，并且把文件名修改为F.fq和R.fq\n",
    "上传后确定文件夹后，在file中输入上传的路径，注意所有的后续文件都会有在这个文件夹中生成，建议每次都新建一个文件夹\n",
    "purpose只有三个选项有意义，1,2或者3，1是针对spacer定位的区域进行扫描并保存截取部分，2是针对碱基编辑器，3是针对spacer定位的区域进行扫描并将全部序列保存，4是针对spacer定位的区域前后特定bp的序列进行保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b93eac-715c-4890-97c6-faf6042522cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./WangHongLe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf53737-af4d-4a15-a28e-f3d9b448d104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of F.fq\n",
      "Started analysis of R.fq\n",
      "Approx 5% complete for R.fq\n",
      "Approx 5% complete for F.fq\n",
      "Approx 10% complete for R.fq\n",
      "Approx 10% complete for F.fq\n",
      "Approx 15% complete for R.fq\n",
      "Approx 15% complete for F.fq\n",
      "Approx 20% complete for R.fq\n",
      "Approx 20% complete for F.fq\n",
      "Approx 25% complete for R.fq\n",
      "Approx 25% complete for F.fq\n",
      "Approx 30% complete for R.fq\n",
      "Approx 30% complete for F.fq\n",
      "Approx 35% complete for R.fq\n",
      "Approx 35% complete for F.fq\n",
      "Approx 40% complete for R.fq\n",
      "Approx 40% complete for F.fq\n",
      "Approx 45% complete for R.fq\n",
      "Approx 45% complete for F.fq\n",
      "Approx 50% complete for R.fq\n",
      "Approx 50% complete for F.fq\n",
      "Approx 55% complete for R.fq\n",
      "Approx 55% complete for F.fq\n",
      "Approx 60% complete for R.fq\n",
      "Approx 60% complete for F.fq\n",
      "Approx 65% complete for R.fq\n",
      "Approx 65% complete for F.fq\n",
      "Approx 70% complete for R.fq\n",
      "Approx 70% complete for F.fq\n",
      "Approx 75% complete for R.fq\n",
      "Approx 75% complete for F.fq\n",
      "Approx 80% complete for R.fq\n",
      "Approx 80% complete for F.fq\n",
      "Approx 85% complete for R.fq\n",
      "Approx 85% complete for F.fq\n",
      "Approx 90% complete for R.fq\n",
      "Approx 90% complete for F.fq\n",
      "Approx 95% complete for R.fq\n",
      "Approx 95% complete for F.fq\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for R.fq\n",
      "Analysis complete for F.fq\n",
      "This is cutadapt 5.1 with Python 3.12.11\n",
      "Command line parameters: -a AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -A AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC -o ./WangHongLe/F.fq.gz -p ./WangHongLe/R.fq.gz --minimum-length 50 --max-n 0 --error-rate 0.1 --json=./WangHongLe/cutadapt.json --cores=14 ../F.fq ../R.fq\n",
      "Processing paired-end reads on 14 cores ...\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total read pairs processed:         23,878,353\n",
      "  Read 1 with adapter:                 622,758 (2.6%)\n",
      "  Read 2 with adapter:                 666,149 (2.8%)\n",
      "\n",
      "== Read fate breakdown ==\n",
      "Pairs that were too short:                   0 (0.0%)\n",
      "Pairs with too many N:                  42,721 (0.2%)\n",
      "Pairs written (passing filters):    23,835,632 (99.8%)\n",
      "\n",
      "Total basepairs processed: 7,163,505,900 bp\n",
      "  Read 1: 3,581,752,950 bp\n",
      "  Read 2: 3,581,752,950 bp\n",
      "Total written (filtered):  7,146,596,545 bp (99.8%)\n",
      "  Read 1: 3,573,367,445 bp\n",
      "  Read 2: 3,573,229,100 bp\n",
      "\n",
      "=== First read: Adapter 1 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT; Type: regular 3'; Length: 33; Trimmed: 622758 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1; 20-29 bp: 2; 30-33 bp: 3\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 80.1%\n",
      "  C: 1.7%\n",
      "  G: 16.4%\n",
      "  T: 1.8%\n",
      "  none/other: 0.0%\n",
      "WARNING:\n",
      "    The adapter is preceded by 'A' extremely often.\n",
      "    The provided adapter sequence could be incomplete at its 5' end.\n",
      "    Ignore this warning when trimming primers.\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t584704\t373099.3\t0\t584704\n",
      "4\t23375\t93274.8\t0\t23375\n",
      "5\t2397\t23318.7\t0\t2397\n",
      "6\t1483\t5829.7\t0\t1483\n",
      "7\t1512\t1457.4\t0\t1512\n",
      "8\t1298\t364.4\t0\t1298\n",
      "9\t1381\t91.1\t0\t1330 51\n",
      "10\t1371\t22.8\t1\t1253 118\n",
      "11\t1336\t5.7\t1\t1242 94\n",
      "12\t1402\t1.4\t1\t1280 122\n",
      "13\t1263\t0.4\t1\t1232 31\n",
      "14\t1233\t0.1\t1\t0 1233\n",
      "15\t3\t0.0\t1\t0 3\n",
      "\n",
      "\n",
      "=== Second read: Adapter 2 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC; Type: regular 3'; Length: 34; Trimmed: 666149 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1; 20-29 bp: 2; 30-34 bp: 3\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 75.3%\n",
      "  C: 1.8%\n",
      "  G: 21.0%\n",
      "  T: 1.9%\n",
      "  none/other: 0.0%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t622447\t373099.3\t0\t622447\n",
      "4\t27507\t93274.8\t0\t27507\n",
      "5\t3777\t23318.7\t0\t3777\n",
      "6\t1422\t5829.7\t0\t1422\n",
      "7\t1524\t1457.4\t0\t1524\n",
      "8\t1334\t364.4\t0\t1334\n",
      "9\t1370\t91.1\t0\t1336 34\n",
      "10\t1379\t22.8\t1\t1291 88\n",
      "11\t1342\t5.7\t1\t1257 85\n",
      "12\t1459\t1.4\t1\t1318 141\n",
      "13\t1320\t0.4\t1\t1286 34\n",
      "14\t1262\t0.1\t1\t0 1262\n",
      "15\t6\t0.0\t1\t0 6\n",
      "\n",
      "\n",
      "WARNING:\n",
      "    One or more of your adapter sequences may be incomplete.\n",
      "    Please see the detailed output above.\n",
      "原始序列对: 23878353\n",
      "保留序列对: 23835632 (99.82%)\n",
      "\n",
      "✅ 保留率符合质控标准(>90%)\n",
      "application/gzip\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of F.fq.gz\n",
      "Started analysis of R.fq.gz\n",
      "Approx 5% complete for F.fq.gz\n",
      "Approx 5% complete for R.fq.gz\n",
      "Approx 10% complete for F.fq.gz\n",
      "Approx 10% complete for R.fq.gz\n",
      "Approx 15% complete for F.fq.gz\n",
      "Approx 15% complete for R.fq.gz\n",
      "Approx 20% complete for F.fq.gz\n",
      "Approx 20% complete for R.fq.gz\n",
      "Approx 25% complete for F.fq.gz\n",
      "Approx 25% complete for R.fq.gz\n",
      "Approx 30% complete for F.fq.gz\n",
      "Approx 30% complete for R.fq.gz\n",
      "Approx 35% complete for F.fq.gz\n",
      "Approx 35% complete for R.fq.gz\n",
      "Approx 40% complete for F.fq.gz\n",
      "Approx 40% complete for R.fq.gz\n",
      "Approx 45% complete for F.fq.gz\n",
      "Approx 45% complete for R.fq.gz\n",
      "Approx 50% complete for F.fq.gz\n",
      "Approx 50% complete for R.fq.gz\n",
      "Approx 55% complete for F.fq.gz\n",
      "Approx 55% complete for R.fq.gz\n",
      "Approx 60% complete for F.fq.gz\n",
      "Approx 60% complete for R.fq.gz\n",
      "Approx 65% complete for F.fq.gz\n",
      "Approx 65% complete for R.fq.gz\n",
      "Approx 70% complete for F.fq.gz\n",
      "Approx 70% complete for R.fq.gz\n",
      "Approx 75% complete for F.fq.gz\n",
      "Approx 75% complete for R.fq.gz\n",
      "Approx 80% complete for F.fq.gz\n",
      "Approx 80% complete for R.fq.gz\n",
      "Approx 85% complete for F.fq.gz\n",
      "Approx 85% complete for R.fq.gz\n",
      "Approx 90% complete for F.fq.gz\n",
      "Approx 90% complete for R.fq.gz\n",
      "Approx 95% complete for F.fq.gz\n",
      "Approx 95% complete for R.fq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for F.fq.gz\n",
      "Analysis complete for R.fq.gz\n"
     ]
    }
   ],
   "source": [
    "strict_QC('../F.fq', '../R.fq', file, primer_f=\"\", primer_r=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf26b36-31a6-4ff1-b757-76509f5e1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd44b86-7d26-45ad-9689-4eb975810013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vsearch v2.30.0_linux_x86_64, 503.5GB RAM, 104 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Merging reads 100%\n",
      "  23835632  Pairs\n",
      "  23426884  Merged (98.3%)\n",
      "    408748  Not merged (1.7%)\n",
      "\n",
      "Pairs that failed merging due to various reasons:\n",
      "    138834  too few kmers found on same diagonal\n",
      "       561  multiple potential alignments\n",
      "     93949  too many differences\n",
      "    175314  alignment score too low, or score drop too high\n",
      "        90  overlap too short\n",
      "\n",
      "Statistics of all reads:\n",
      "    149.91  Mean read length\n",
      "\n",
      "Statistics of merged reads:\n",
      "    212.74  Mean fragment length\n",
      "     11.68  Standard deviation of fragment length\n",
      "      0.21  Mean expected error in forward sequences\n",
      "      0.21  Mean expected error in reverse sequences\n",
      "      0.17  Mean expected error in merged sequences\n",
      "      0.12  Mean observed errors in merged region of forward sequences\n",
      "      0.09  Mean observed errors in merged region of reverse sequences\n",
      "      0.21  Mean observed errors in merged region\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "双端合并完成 → ./WangHongLe/merged.fasta\n",
      "null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of merged.fasta\n",
      "Approx 5% complete for merged.fasta\n",
      "Approx 10% complete for merged.fasta\n",
      "Approx 15% complete for merged.fasta\n",
      "Approx 20% complete for merged.fasta\n",
      "Approx 25% complete for merged.fasta\n",
      "Approx 30% complete for merged.fasta\n",
      "Approx 35% complete for merged.fasta\n",
      "Approx 40% complete for merged.fasta\n",
      "Approx 45% complete for merged.fasta\n",
      "Approx 50% complete for merged.fasta\n",
      "Approx 55% complete for merged.fasta\n",
      "Approx 60% complete for merged.fasta\n",
      "Approx 65% complete for merged.fasta\n",
      "Approx 70% complete for merged.fasta\n",
      "Approx 75% complete for merged.fasta\n",
      "Approx 80% complete for merged.fasta\n",
      "Approx 85% complete for merged.fasta\n",
      "Approx 90% complete for merged.fasta\n",
      "Approx 95% complete for merged.fasta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for merged.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TrimmomaticSE: Started with arguments:\n",
      " -threads 14 -phred33 ./WangHongLe/merged.fasta ./WangHongLe/output_trimmed.fastq LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15\n",
      "Input Reads: 23426884 Surviving: 23423487 (99.99%) Dropped: 3397 (0.01%)\n",
      "TrimmomaticSE: Completed successfully\n",
      "Processing sequences: 23423487it [21:40, 18004.59it/s]\n",
      "31it [00:17,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "NGS(file,purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "636a26fe-2bc9-4792-be49-f4397c6089c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41fe7137-8eca-4583-8d54-016120277e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 ./WangHongLe/merged.fasta 已存在，跳过合并操作\n",
      "文件 ./WangHongLe/output_trimmed.fastq 已存在，跳过质量控制和修剪步骤\n",
      "所有输出文件已存在，跳过分类操作。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:16,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "NGS(file,purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f39970b-0bb1-468a-b583-7882000870df",
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "013f48f3-4f4f-47f4-b1cb-ce9a9feaaf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 ./WangHongLe/merged.fasta 已存在，跳过合并操作\n",
      "文件 ./WangHongLe/output_trimmed.fastq 已存在，跳过质量控制和修剪步骤\n",
      "所有输出文件已存在，跳过分类操作。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:17,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "NGS(file,purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51180eed-9832-4198-9d2d-035075dc1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose = 4\n",
    "spacer_front=20\n",
    "spacer_after=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10b83ff7-279b-4a5a-8996-a0897413bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 ./WangHongLe/merged.fasta 已存在，跳过合并操作\n",
      "文件 ./WangHongLe/output_trimmed.fastq 已存在，跳过质量控制和修剪步骤\n",
      "所有输出文件已存在，跳过分类操作。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spacer surrounding sequences: 31it [00:21,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "NGS(file,purpose,spacer_front,spacer_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb71f3a-aac8-4fdd-a520-482d3f546f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
